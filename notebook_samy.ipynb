{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aaa3bd0",
   "metadata": {},
   "source": [
    "# Recherche de production solaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fe6ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "df = pd.read_csv(\"data/prod_solaire.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e786f10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df.iloc[:, 1] < 100)  & (df.iloc[:, 1] > 0)]\n",
    "types = [\"hydro\", \"eolienne\", \"solar\"]\n",
    "print(f\"Please enter any of types in this list : {types} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d6e963",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b290ece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = df.isnull().sum()\n",
    "\n",
    "display(df_missing)\n",
    "\n",
    "df_ext = df.sort_values(by=[\"prod_solaire\"], ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3168ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df.loc[df[\"prod_solaire\"] > 0].sort_values(by=\"prod_solaire\")\n",
    "\n",
    "df[\"date\"].dt.dayofweek.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f646981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openmeteo_requests\n",
    "\n",
    "import pandas as pd\n",
    "import requests_cache\n",
    "from retry_requests import retry\n",
    "\n",
    "# Setup the Open-Meteo API client with cache and retry on error\n",
    "cache_session = requests_cache.CachedSession('.cache', expire_after = -1)\n",
    "retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "openmeteo = openmeteo_requests.Client(session = retry_session)\n",
    "\n",
    "# Make sure all required weather variables are listed here\n",
    "# The order of variables in hourly or daily is important to assign them correctly below\n",
    "url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "params = {\n",
    "\t\"latitude\": 43.6109,\n",
    "\t\"longitude\": 3.8763,\n",
    "\t\"start_date\": \"2016-09-01\",\n",
    "\t\"end_date\": \"2025-09-25\",\n",
    "\t\"hourly\": [\"global_tilted_irradiance\", \"temperature_2m\", \"relative_humidity_2m\", \"precipitation\", \"wind_speed_50m\", \"wind_direction_10m\"],\n",
    "\t\"tilt\": 35,\n",
    "}\n",
    "responses = openmeteo.weather_api(url, params=params)\n",
    "\n",
    "# Process first location. Add a for-loop for multiple locations or weather models\n",
    "response = responses[0]\n",
    "print(f\"Coordinates: {response.Latitude()}°N {response.Longitude()}°E\")\n",
    "print(f\"Elevation: {response.Elevation()} m asl\")\n",
    "print(f\"Timezone difference to GMT+0: {response.UtcOffsetSeconds()}s\")\n",
    "\n",
    "# Process hourly data. The order of variables needs to be the same as requested.\n",
    "hourly = response.Hourly()\n",
    "hourly_global_tilted_irradiance = hourly.Variables(0).ValuesAsNumpy()\n",
    "hourly_temperature_2m = hourly.Variables(1).ValuesAsNumpy()\n",
    "hourly_relative_humidity_2m = hourly.Variables(2).ValuesAsNumpy()\n",
    "hourly_precipitation = hourly.Variables(3).ValuesAsNumpy()\n",
    "hourly_wind_speed_50m = hourly.Variables(4).ValuesAsNumpy()\n",
    "hourly_wind_direction_10m = hourly.Variables(5).ValuesAsNumpy()\n",
    "\n",
    "hourly_data = {\"date\": pd.date_range(\n",
    "\tstart = pd.to_datetime(hourly.Time(), unit = \"s\", utc = True),\n",
    "\tend = pd.to_datetime(hourly.TimeEnd(), unit = \"s\", utc = True),\n",
    "\tfreq = pd.Timedelta(seconds = hourly.Interval()),\n",
    "\tinclusive = \"left\"\n",
    ")}\n",
    "\n",
    "hourly_data[\"global_tilted_irradiance\"] = hourly_global_tilted_irradiance\n",
    "hourly_data[\"temperature_2m\"] = hourly_temperature_2m\n",
    "hourly_data[\"relative_humidity_2m\"] = hourly_relative_humidity_2m\n",
    "hourly_data[\"precipitation\"] = hourly_precipitation\n",
    "hourly_data[\"wind_speed_50m\"] = hourly_wind_speed_50m\n",
    "hourly_data[\"wind_direction_10m\"] = hourly_wind_direction_10m\n",
    "\n",
    "hourly_dataframe = pd.DataFrame(data = hourly_data)\n",
    "print(\"\\nHourly data\\n\", hourly_global_tilted_irradiance)\n",
    "gti_df = hourly_dataframe[\"global_tilted_irradiance\"]\n",
    "\n",
    "print(gti_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2a0c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPES = (\"hydro\", \"eolienne\", \"solaire\")\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/raw/prod_hydro.csv\")\n",
    "\n",
    "def clean(df: pd.DataFrame, energy_type: str) -> pd.DataFrame:\n",
    "      df.iloc[:, 1] = df.iloc[:, 1].abs()\n",
    "      if energy_type not in TYPES:\n",
    "        print(f\"Please enter any of types in this list : {TYPES} \")\n",
    "      elif energy_type == \"hydro\":\n",
    "        df = df.loc[(df.iloc[:, 1] <= 200)  & (df.iloc[:, 1] > 0)].copy()\n",
    "        df = df.rename(columns={\"date_obs_elab\" : \"date\"})\n",
    "      elif energy_type == \"eolienne\":\n",
    "        df = df.loc[(df.iloc[:, 1] <= 100)  & (df.iloc[:, 1] > 0)].copy()\n",
    "      elif energy_type == \"solaire\":\n",
    "        df = df.loc[(df.iloc[:, 1] <= 100)  & (df.iloc[:, 1] > 0)].copy()\n",
    "        df.iloc[:, 1] = df.iloc[:, 1]*1.5\n",
    "      df = df.drop_duplicates(subset=\"date\", keep=\"last\")\n",
    "      df = df.sort_values(by=\"date\")\n",
    "      df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "      df = df.dropna().reset_index(drop=True)\n",
    "      df[\"date\"] = df[\"date\"].dt.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "      return df\n",
    "\n",
    "df_clean = clean(df, \"hydro\")\n",
    "display(df_clean)\n",
    "records = df.to_dict(orient=\"records\")\n",
    "print(records)\n",
    "\n",
    "# df_clean.loc[df_clean[\"prod_hydro\"].duplicated() == True]\n",
    "# df_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596053a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.access(os.getcwd()+\"/data/train\", os.F_OK) is False:\n",
    "    os.makedirs(str(os.getcwd()) + \"/data/train\")\n",
    "\n",
    "type(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f63047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from supabase import create_client\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, Float, Integer, DateTime, text\n",
    "from sqlalchemy.pool import NullPool\n",
    "\n",
    "load_dotenv()\n",
    "types = (\"hydro\", \"solaire\", \"eolienne\")\n",
    "TYPES = os.getenv(\"types\")\n",
    "USER = os.getenv(\"user\")\n",
    "PASSWORD = os.getenv(\"password\")\n",
    "HOST = os.getenv(\"host\")\n",
    "PORT = os.getenv(\"port\")\n",
    "DBNAME = os.getenv(\"dbname\")\n",
    "URL = os.getenv(\"SUPABASE_URL\")\n",
    "SERVICE_ROLE_KEY = os.getenv(\"SUPABASE_SERVICE_ROLE_KEY\")\n",
    "DATABASE_URL = f\"postgresql+psycopg2://{USER}:{PASSWORD}@{HOST}:{PORT}/{DBNAME}?sslmode=require\"\n",
    "\n",
    "client = create_client(URL, SERVICE_ROLE_KEY)\n",
    "engine = create_engine(DATABASE_URL, poolclass=NullPool)\n",
    "meta = MetaData()\n",
    "\n",
    "def fetch_data(energy_type:str, file_path:str = os.path.join(os.getcwd(), \"data/train/\")):\n",
    "        if os.access(file_path, os.F_OK) is False:\n",
    "            os.makedirs(file_path)\n",
    "        if energy_type in (None, \"solaire\"):\n",
    "            with engine.begin() as conn:\n",
    "                solaire_table = Table(\"Solaire_data\", meta, autoload_with=engine)\n",
    "                result_solaire = conn.execute(solaire_table.select())\n",
    "                df_solaire = pd.DataFrame(sorted(result_solaire))\n",
    "                return df_solaire.to_csv(file_path+\"solaire_train.csv\")\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "            # data_solaire = (client.table(\"Solaire_data\").select(\"*\").order(\"date\", desc=False).execute())\n",
    "            # print(data_solaire.data[1])\n",
    "            # for row in range(len(data_solaire.data)):\n",
    "            #     df_solaire = pd.DataFrame(data_solaire.data, columns = data_solaire.data[row].keys())\n",
    "            #     df_solaire = df_solaire.sort_values(by=\"id\").reset_index(drop=True)\n",
    "            # return df_solaire\n",
    "            # df_solaire.to_csv(file_path+\"solaire_train.csv\")\n",
    "        if energy_type in (None, \"eolienne\"):\n",
    "            data_eolienne = (client.table(\"Eolienne_data\").select(\"*\").execute())\n",
    "            df_eolienne = pd.DataFrame(data_eolienne)\n",
    "            df_eolienne.to_csv(file_path+\"eolienne_train.csv\")\n",
    "        if energy_type in (None, \"hydro\"):\n",
    "            data_hydro = (client.table(\"Hydro_data\").select(\"*\").execute())\n",
    "            df_hydro = pd.DataFrame(data_hydro)\n",
    "            df_hydro.to_csv(file_path+\"hydro_train.csv\")\n",
    "\n",
    "fetch_data(\"solaire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6da86cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openmeteo_requests\n",
    "\n",
    "import pandas as pd\n",
    "import requests_cache\n",
    "from retry_requests import retry\n",
    "\n",
    "# Setup the Open-Meteo API client with cache and retry on error\n",
    "cache_session = requests_cache.CachedSession('.cache', expire_after = -1)\n",
    "retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "openmeteo = openmeteo_requests.Client(session = retry_session)\n",
    "\n",
    "url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "params = {\n",
    "\t\"latitude\": 43.6109,\n",
    "\t\"longitude\": 3.8763,\n",
    "\t\"start_date\": \"2016-09-01\",\n",
    "\t\"end_date\": \"2025-09-25\",\n",
    "\t\"hourly\": [\"global_tilted_irradiance\", \"temperature_2m\", \"relative_humidity_2m\", \"precipitation\", \"wind_speed_10m\", \"wind_direction_10m\"],\n",
    "\t\"tilt\": 35,\n",
    "}\n",
    "responses = openmeteo.weather_api(url, params=params)\n",
    "response = responses[0]\n",
    "hourly = response.Hourly()\n",
    "\n",
    "hourly_global_tilted_irradiance = hourly.Variables(0).ValuesAsNumpy()\n",
    "hourly_temperature_2m = hourly.Variables(1).ValuesAsNumpy()\n",
    "hourly_relative_humidity_2m = hourly.Variables(2).ValuesAsNumpy()\n",
    "hourly_precipitation = hourly.Variables(3).ValuesAsNumpy()\n",
    "hourly_wind_speed_10m = hourly.Variables(4).ValuesAsNumpy()\n",
    "hourly_wind_direction_10m = hourly.Variables(5).ValuesAsNumpy()\n",
    "\n",
    "hourly_data = {\"date\": pd.date_range(\n",
    "\tstart = pd.to_datetime(hourly.Time(), unit = \"s\", utc = True),\n",
    "\tend = pd.to_datetime(hourly.TimeEnd(), unit = \"s\", utc = True),\n",
    "\tfreq = pd.Timedelta(seconds = hourly.Interval()),\n",
    "\tinclusive = \"left\"\n",
    ")}\n",
    "\n",
    "print(hourly_data)\n",
    "# def load_api(energy_type, url, parameters:list) -> pd.DataFrame:\n",
    "        \n",
    "#     if energy_type == \"solaire\":\n",
    "#         all_data = []\n",
    "#         for param in parameters:\n",
    "#             params = {\"grandeur_solaire_elab\": param, \"size\": 1500}\n",
    "#             response = requests.get(url, params=params)\n",
    "#             df = pd.DataFrame(response.json().get(\"data\", []))\n",
    "#             if not df.empty:\n",
    "#                 df[\"grandeur_solaire_elab\"] = param\n",
    "#                 all_data.append(df)\n",
    "#         if all_data:\n",
    "#             return pd.concat(all_data, ignore_index=True)\n",
    "#         return pd.DataFrame()\n",
    "\n",
    "# load_api(\"solaire\", url, [\"global_tilted_irradiance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688e0be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "url = \"https://hubeau.eaufrance.fr/api/v2/hydrometrie/observations_tr\"\n",
    "parameters = {\n",
    "    \"code_entite\": \"Y321002101\",\n",
    "    \"grandeur_hydro_elab\": [\"QmnJ\", \"HIXnJ\"],\n",
    "    \"date_debut_obs\": \"2022-09-01\",\n",
    "    \"date_fin_obs\": \"2025-09-29\",\n",
    "    \"size\": 1800,\n",
    "    \"page\":1\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=parameters)\n",
    "response.raise_for_status()\n",
    "\n",
    "data = response.json().get(\"data\", [])\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def clean(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df.empty:\n",
    "        print(\"Aucune donnée API\")\n",
    "        return df\n",
    "\n",
    "    date_col = \"date_obs_elab\" if \"date_obs_elab\" in df.columns else \"date_obs\"\n",
    "    g_col    = \"grandeur_hydro_elab\" if \"grandeur_hydro_elab\" in df.columns else \"grandeur_hydro\"\n",
    "    v_col    = \"resultat_obs_elab\" if \"resultat_obs_elab\" in df.columns else \"resultat_obs\"\n",
    "\n",
    "    print(\"Dates min/max :\", df[date_col].min(), \"→\", df[date_col].max())\n",
    "    print(\"Grandeurs uniques :\", df[g_col].dropna().unique()[:20])\n",
    "\n",
    "    missing = {date_col, g_col, v_col} - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Colonnes manquantes: {missing}\")\n",
    "\n",
    "    df = df[[date_col, g_col, v_col]].copy()\n",
    "    df[\"date\"] = pd.to_datetime(df[date_col], errors=\"coerce\").dt.normalize()\n",
    "\n",
    "    s = df[g_col].astype(\"string\").str.upper().str.strip()\n",
    "    df[\"norme\"] = pd.Series(pd.NA, index=df.index, dtype=\"string\")\n",
    "    df.loc[s.str.startswith(\"Q\"), \"norme\"] = \"QmnJ\"\n",
    "    df.loc[s.str.startswith(\"H\"), \"norme\"] = \"HIXnJ\"\n",
    "\n",
    "    df = df[df[\"norme\"].notna() & df[\"date\"].notna()].copy()\n",
    "\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=[\"date\", \"QmnJ\", \"HIXnJ\"])\n",
    "\n",
    "    wide = (\n",
    "        df.pivot_table(\n",
    "            index=\"date\",\n",
    "            columns=\"norme\",\n",
    "            values=v_col,\n",
    "            aggfunc=\"mean\",\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    for c in [\"QmnJ\", \"HIXnJ\"]:\n",
    "        if c not in wide.columns:\n",
    "            wide[c] = np.nan\n",
    "    wide[[\"QmnJ\", \"HIXnJ\"]] = wide[[\"QmnJ\", \"HIXnJ\"]].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    wide = wide.sort_values(\"date\").reset_index(drop=True)\n",
    "    wide[\"date\"] = wide[\"date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    return wide[[\"date\", \"QmnJ\", \"HIXnJ\"]]\n",
    "\n",
    "print(clean(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0371ea1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "400 Client Error: Bad Request for url: https://hubeau.eaufrance.fr/api/v2/hydrometrie/obs_elab?code_entite=Y321002101&grandeur_hydro_elab=QmJ&date_debut_obs_elab=2022-09-01&date_fin_obs_elab=2025-09-29&size=1500",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 110\u001b[39m\n\u001b[32m    106\u001b[39m     out = out[[\u001b[33m\"\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mQmnJ\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mHIXnJ\u001b[39m\u001b[33m\"\u001b[39m]].fillna(\u001b[32m0\u001b[39m)\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m df = \u001b[43mload_api2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m df_clean = clean(df)\n\u001b[32m    112\u001b[39m df_clean\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mload_api2\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     28\u001b[39m     params = {\n\u001b[32m     29\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcode_entite\u001b[39m\u001b[33m\"\u001b[39m: code_entite, \n\u001b[32m     30\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mgrandeur_hydro_elab\u001b[39m\u001b[33m\"\u001b[39m: grandeur, \n\u001b[32m     31\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdate_debut_obs_elab\u001b[39m\u001b[33m\"\u001b[39m : \u001b[33m\"\u001b[39m\u001b[33m2022-09-01\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     32\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdate_fin_obs_elab\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m2025-09-29\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     33\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msize\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1500\u001b[39m,}\n\u001b[32m     34\u001b[39m     response = requests.get(url, params=params)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     df = pd.DataFrame(response.json().get(\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m, []))\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df.empty:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/production_enr/.venv/lib/python3.12/site-packages/requests/models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1021\u001b[39m     http_error_msg = (\n\u001b[32m   1022\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1023\u001b[39m     )\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 400 Client Error: Bad Request for url: https://hubeau.eaufrance.fr/api/v2/hydrometrie/obs_elab?code_entite=Y321002101&grandeur_hydro_elab=QmJ&date_debut_obs_elab=2022-09-01&date_fin_obs_elab=2025-09-29&size=1500"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "all_data = []\n",
    "grandeurs = [\"QmJ\", \"HIXnJ\"]\n",
    "url = \"https://hubeau.eaufrance.fr/api/v2/hydrometrie/obs_elab\"\n",
    "code_entite = \"Y321002101\"\n",
    "\n",
    "def load_api() -> pd.DataFrame:\n",
    "        for grandeur in grandeurs:\n",
    "            params = {\n",
    "                      \"code_entite\": code_entite, \n",
    "                      \"grandeur_hydro_elab\": grandeur, \n",
    "                      \"date_debut_obs\" : \"2022-09-01\",\n",
    "                      \"date_fin_obs\": \"2025-09-29\",\n",
    "                      \"size\": 1500,}\n",
    "            response = requests.get(url, params=params)\n",
    "            response.raise_for_status()\n",
    "            df = pd.DataFrame(response.json().get(\"data\", []))\n",
    "            if not df.empty:\n",
    "                df[\"grandeur_hydro_elab\"] = grandeur\n",
    "                all_data.append(df)\n",
    "        if all_data:\n",
    "            return pd.concat(all_data, ignore_index=True)\n",
    "        return df\n",
    "\n",
    "def load_api2():\n",
    "    for grandeur in grandeurs:\n",
    "        params = {\n",
    "            \"code_entite\": code_entite, \n",
    "            \"grandeur_hydro_elab\": grandeur, \n",
    "            \"date_debut_obs_elab\" : \"2022-09-01\",\n",
    "            \"date_fin_obs_elab\": \"2025-09-29\",\n",
    "            \"size\": 1500,}\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()\n",
    "        df = pd.DataFrame(response.json().get(\"data\", []))\n",
    "    if not df.empty:\n",
    "        df[\"grandeur_hydro_elab\"] = grandeur\n",
    "        all_data.append(df)\n",
    "    if all_data:\n",
    "        return pd.concat(all_data, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def clean(df: pd.DataFrame,\n",
    "          start=\"2022-01-01\",\n",
    "          end=None,\n",
    "          expected_cols=(\"QmJ\", \"HIXnJ\")) -> pd.DataFrame:\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"Aucune donnée API\")\n",
    "        end = end or date.today().isoformat()\n",
    "        idx = pd.date_range(start, end, freq=\"D\")\n",
    "        out = pd.DataFrame(index=idx).reset_index().rename(columns={\"index\": \"date\"})\n",
    "        out.insert(0, \"id\", range(1, len(out) + 1))\n",
    "        return out\n",
    "    \n",
    "    df = df.copy()\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date_obs_elab\"]).dt.normalize()\n",
    "    df = df[[\"date\", \"grandeur_hydro_elab\", \"resultat_obs_elab\"]]\n",
    "\n",
    "    df_pivot = (\n",
    "        df.pivot_table(\n",
    "            index=\"date\",\n",
    "            columns=\"grandeur_hydro_elab\",\n",
    "            values=\"resultat_obs_elab\",\n",
    "            aggfunc=\"mean\"\n",
    "        )\n",
    "        .sort_index()\n",
    "    )\n",
    "\n",
    "    end = end or date.today().isoformat()\n",
    "    full_idx = pd.date_range(start, end, freq=\"D\")\n",
    "    df_pivot = df_pivot.reindex(full_idx)\n",
    "\n",
    "    present_cols = [c for c in expected_cols if c in df_pivot.columns]\n",
    "    if not present_cols:\n",
    "        out = df_pivot.reset_index().rename(columns={\"index\": \"date\"})\n",
    "        out.insert(0, \"id\", range(1, len(out) + 1))\n",
    "        return out\n",
    "\n",
    "    df_pivot = df_pivot[present_cols]\n",
    "    for col in df_pivot.columns:\n",
    "        df_pivot[col] = pd.to_numeric(df_pivot[col], errors=\"coerce\")\n",
    "\n",
    "    bounds_max = {\n",
    "        \"QmJ\": 10000,\n",
    "        \"HIXnJ\": 2000 \n",
    "    }\n",
    "    for col in df_pivot.columns:\n",
    "        df_pivot[col] = df_pivot[col].where(df_pivot[col] > 0)\n",
    "        if col in bounds_max:\n",
    "            df_pivot[col] = df_pivot[col].where(df_pivot[col] < bounds_max[col])\n",
    "\n",
    "    for col in df_pivot.columns:\n",
    "        series = df_pivot[col].dropna()\n",
    "        if series.empty:\n",
    "            continue\n",
    "        Q1 = series.quantile(0.25)\n",
    "        Q3 = series.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        low = Q1 - 1.5 * IQR\n",
    "        high = Q3 + 1.5 * IQR\n",
    "        df_pivot[col] = df_pivot[col].where((df_pivot[col] >= low) & (df_pivot[col] <= high))\n",
    "\n",
    "    out = df_pivot.reset_index().rename(columns={\"index\": \"date\"})\n",
    "    out = out[[\"date\",\"QmJ\", \"HIXnJ\"]].fillna(0)\n",
    "\n",
    "    return out\n",
    "\n",
    "df = load_api2()\n",
    "df_clean = clean(df)\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c9a092c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "global_tilted_irradiance",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "temperature_2m",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "ref": "8ce4f599-5ec7-4b62-ac88-d27fd179635b",
       "rows": [
        [
         "0",
         "2016-09-01 00:00:00+00:00",
         "6863.28",
         "626.812"
        ],
        [
         "1",
         "2016-09-02 00:00:00+00:00",
         "7161.4395",
         "617.012"
        ],
        [
         "2",
         "2016-09-03 00:00:00+00:00",
         "6725.4814",
         "608.162"
        ],
        [
         "3",
         "2016-09-04 00:00:00+00:00",
         "6229.299",
         "633.662"
        ],
        [
         "4",
         "2016-09-05 00:00:00+00:00",
         "6940.6807",
         "640.262"
        ],
        [
         "5",
         "2016-09-06 00:00:00+00:00",
         "7067.3853",
         "637.912"
        ],
        [
         "6",
         "2016-09-07 00:00:00+00:00",
         "6819.285",
         "554.212"
        ],
        [
         "7",
         "2016-09-08 00:00:00+00:00",
         "6166.001",
         "566.962"
        ],
        [
         "8",
         "2016-09-09 00:00:00+00:00",
         "5990.473",
         "609.812"
        ],
        [
         "9",
         "2016-09-10 00:00:00+00:00",
         "6494.264",
         "597.162"
        ],
        [
         "10",
         "2016-09-11 00:00:00+00:00",
         "6174.3057",
         "607.012"
        ],
        [
         "11",
         "2016-09-12 00:00:00+00:00",
         "6506.5386",
         "567.912"
        ],
        [
         "12",
         "2016-09-13 00:00:00+00:00",
         "6480.2563",
         "559.812"
        ],
        [
         "13",
         "2016-09-14 00:00:00+00:00",
         "1546.543",
         "480.762"
        ],
        [
         "14",
         "2016-09-15 00:00:00+00:00",
         "6185.725",
         "447.312"
        ],
        [
         "15",
         "2016-09-16 00:00:00+00:00",
         "5484.069",
         "468.612"
        ],
        [
         "16",
         "2016-09-17 00:00:00+00:00",
         "5768.272",
         "448.16202"
        ],
        [
         "17",
         "2016-09-18 00:00:00+00:00",
         "4827.2866",
         "440.812"
        ],
        [
         "18",
         "2016-09-19 00:00:00+00:00",
         "6327.6377",
         "491.762"
        ],
        [
         "19",
         "2016-09-20 00:00:00+00:00",
         "6392.082",
         "475.66202"
        ],
        [
         "20",
         "2016-09-21 00:00:00+00:00",
         "6245.3325",
         "457.762"
        ],
        [
         "21",
         "2016-09-22 00:00:00+00:00",
         "6757.0044",
         "446.812"
        ],
        [
         "22",
         "2016-09-23 00:00:00+00:00",
         "5567.8037",
         "452.062"
        ],
        [
         "23",
         "2016-09-24 00:00:00+00:00",
         "5968.3853",
         "460.662"
        ],
        [
         "24",
         "2016-09-25 00:00:00+00:00",
         "4513.3467",
         "454.062"
        ],
        [
         "25",
         "2016-09-26 00:00:00+00:00",
         "5724.748",
         "474.162"
        ],
        [
         "26",
         "2016-09-27 00:00:00+00:00",
         "6377.535",
         "475.412"
        ],
        [
         "27",
         "2016-09-28 00:00:00+00:00",
         "6504.362",
         "479.812"
        ],
        [
         "28",
         "2016-09-29 00:00:00+00:00",
         "6548.7354",
         "452.062"
        ],
        [
         "29",
         "2016-09-30 00:00:00+00:00",
         "4187.2676",
         "465.962"
        ],
        [
         "30",
         "2016-10-01 00:00:00+00:00",
         "2892.421",
         "453.012"
        ],
        [
         "31",
         "2016-10-02 00:00:00+00:00",
         "3989.8872",
         "430.062"
        ],
        [
         "32",
         "2016-10-03 00:00:00+00:00",
         "6558.536",
         "417.412"
        ],
        [
         "33",
         "2016-10-04 00:00:00+00:00",
         "6538.0903",
         "414.062"
        ],
        [
         "34",
         "2016-10-05 00:00:00+00:00",
         "5798.755",
         "417.562"
        ],
        [
         "35",
         "2016-10-06 00:00:00+00:00",
         "1455.4069",
         "326.812"
        ],
        [
         "36",
         "2016-10-07 00:00:00+00:00",
         "5324.63",
         "350.362"
        ],
        [
         "37",
         "2016-10-08 00:00:00+00:00",
         "6465.8096",
         "375.462"
        ],
        [
         "38",
         "2016-10-09 00:00:00+00:00",
         "6487.05",
         "353.462"
        ],
        [
         "39",
         "2016-10-10 00:00:00+00:00",
         "6199.38",
         "320.862"
        ],
        [
         "40",
         "2016-10-11 00:00:00+00:00",
         "6341.585",
         "310.91202"
        ],
        [
         "41",
         "2016-10-12 00:00:00+00:00",
         "4172.1685",
         "330.462"
        ],
        [
         "42",
         "2016-10-13 00:00:00+00:00",
         "812.5052",
         "340.312"
        ],
        [
         "43",
         "2016-10-14 00:00:00+00:00",
         "2434.0955",
         "363.362"
        ],
        [
         "44",
         "2016-10-15 00:00:00+00:00",
         "5427.517",
         "320.862"
        ],
        [
         "45",
         "2016-10-16 00:00:00+00:00",
         "3481.1667",
         "390.762"
        ],
        [
         "46",
         "2016-10-17 00:00:00+00:00",
         "1407.0887",
         "403.662"
        ],
        [
         "47",
         "2016-10-18 00:00:00+00:00",
         "5891.0107",
         "380.062"
        ],
        [
         "48",
         "2016-10-19 00:00:00+00:00",
         "6152.642",
         "334.862"
        ],
        [
         "49",
         "2016-10-20 00:00:00+00:00",
         "5947.1763",
         "298.912"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 3312
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>global_tilted_irradiance</th>\n",
       "      <th>temperature_2m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-09-01 00:00:00+00:00</td>\n",
       "      <td>6863.279785</td>\n",
       "      <td>626.812012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-09-02 00:00:00+00:00</td>\n",
       "      <td>7161.439453</td>\n",
       "      <td>617.012024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-09-03 00:00:00+00:00</td>\n",
       "      <td>6725.481445</td>\n",
       "      <td>608.161987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-09-04 00:00:00+00:00</td>\n",
       "      <td>6229.298828</td>\n",
       "      <td>633.661987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-09-05 00:00:00+00:00</td>\n",
       "      <td>6940.680664</td>\n",
       "      <td>640.262024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3307</th>\n",
       "      <td>2025-09-21 00:00:00+00:00</td>\n",
       "      <td>2806.606689</td>\n",
       "      <td>500.795990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3308</th>\n",
       "      <td>2025-09-22 00:00:00+00:00</td>\n",
       "      <td>5779.825684</td>\n",
       "      <td>435.496002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3309</th>\n",
       "      <td>2025-09-23 00:00:00+00:00</td>\n",
       "      <td>5843.613770</td>\n",
       "      <td>358.295990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310</th>\n",
       "      <td>2025-09-24 00:00:00+00:00</td>\n",
       "      <td>5426.826172</td>\n",
       "      <td>348.295990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>2025-09-25 00:00:00+00:00</td>\n",
       "      <td>4822.087402</td>\n",
       "      <td>367.895996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3312 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          date  global_tilted_irradiance  temperature_2m\n",
       "0    2016-09-01 00:00:00+00:00               6863.279785      626.812012\n",
       "1    2016-09-02 00:00:00+00:00               7161.439453      617.012024\n",
       "2    2016-09-03 00:00:00+00:00               6725.481445      608.161987\n",
       "3    2016-09-04 00:00:00+00:00               6229.298828      633.661987\n",
       "4    2016-09-05 00:00:00+00:00               6940.680664      640.262024\n",
       "...                        ...                       ...             ...\n",
       "3307 2025-09-21 00:00:00+00:00               2806.606689      500.795990\n",
       "3308 2025-09-22 00:00:00+00:00               5779.825684      435.496002\n",
       "3309 2025-09-23 00:00:00+00:00               5843.613770      358.295990\n",
       "3310 2025-09-24 00:00:00+00:00               5426.826172      348.295990\n",
       "3311 2025-09-25 00:00:00+00:00               4822.087402      367.895996\n",
       "\n",
       "[3312 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from supabase import create_client, Client\n",
    "from abc import ABC, abstractmethod\n",
    "from dotenv import load_dotenv\n",
    "from retry_requests import retry\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import requests\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "import os\n",
    "\n",
    "\n",
    "cache_session = requests_cache.CachedSession('.cache', expire_after = -1)\n",
    "retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "openmeteo = openmeteo_requests.Client(session = retry_session)\n",
    "\n",
    "api_url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "params = {\n",
    "\"latitude\": 43.6109,\n",
    "\"longitude\": 3.8763,\n",
    "\"start_date\": \"2016-09-01\",\n",
    "\"end_date\": \"2025-09-25\",\n",
    "\"hourly\": [\"global_tilted_irradiance\", \"temperature_2m\"],\n",
    "\"tilt\": 35,\n",
    "}\n",
    "responses = openmeteo.weather_api(api_url, params=params)\n",
    "hourly = responses[0].Hourly()\n",
    "hourly_global_tilted_irradiance = hourly.Variables(0).ValuesAsNumpy()\n",
    "hourly_temperature_2m = hourly.Variables(1).ValuesAsNumpy()\n",
    "\n",
    "hourly_data = {\"date\": pd.date_range(\n",
    "start = pd.to_datetime(hourly.Time(), unit = \"s\", utc = True),\n",
    "end = pd.to_datetime(hourly.TimeEnd(), unit = \"s\", utc = True),\n",
    "freq = pd.Timedelta(seconds = hourly.Interval()),\n",
    "inclusive = \"left\"\n",
    ")}\n",
    "hourly_data[\"global_tilted_irradiance\"] = hourly_global_tilted_irradiance\n",
    "hourly_data[\"temperature_2m\"] = hourly_temperature_2m\n",
    "hourly_dataframe = pd.DataFrame(data = hourly_data)\n",
    "daily_dataframe= hourly_dataframe.resample('D', on='date').sum()\n",
    "daily_dataframe = daily_dataframe.reset_index().rename(columns={\"index\": \"date\"})\n",
    "daily_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f39473",
   "metadata": {},
   "outputs": [],
   "source": [
    "if self.energy_type == \"hydro\":\n",
    "        df = df.loc[(df.iloc[:, 1] <= 200)  & (df.iloc[:, 1] > 0)].copy()\n",
    "        df = df.rename(columns={\"date_obs_elab\" : \"date\"})\n",
    "      elif self.energy_type == \"eolienne\":\n",
    "        df = df.loc[(df.iloc[:, 1] <= 100)  & (df.iloc[:, 1] > 0)].copy()\n",
    "      elif self.energy_type == \"solaire\":\n",
    "        df = df.loc[(df.iloc[:, 1] <= 100)  & (df.iloc[:, 1] > 0)].copy()\n",
    "        df.iloc[:, 1] = df.iloc[:, 1]*1.5\n",
    "      df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "      df = df.sort_values(by=\"date\")\n",
    "      df = df.drop_duplicates(subset=\"date\", keep=\"first\")\n",
    "      df = df.dropna().reset_index(drop=True)\n",
    "      df[\"date\"] = df[\"date\"].dt.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "      return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "production-enr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
